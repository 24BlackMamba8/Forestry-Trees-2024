# -*- coding: utf-8 -*-
# =========================
# ğŸ“ ×¢×¨×¢×•×¨×™× â€” ×¤×™×œ×•×—×™× ×•×’×¨×¤×™× (×“×£ ×¢×¦×××™)
# =========================
# pages/ğŸ“BI_×“×•×—×•×ª_×¢×¨×¢×•×¨×™×.py

import re
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.io as pio

from style_pack import inject_base_css, apply_plotly_theme, hero_header, glass_container

# ---------- ×¢×™×¦×•×‘ ×¢××•×“ ----------
st.set_page_config(page_title="BI â€“ ×¢×¨×¢×•×¨×™×", layout="wide")
apply_plotly_theme()
inject_base_css(bg_main="assets/bg_main.jpg", bg_sidebar="assets/bg_sidebar.jpg")
hero_header("ğŸ“Š BI â€“ ×¢×¨×¢×•×¨×™×", "× ×™×ª×•×— ×¢×¨×¢×•×¨×™×: ×¤×™×œ×•×—×™×, ×”×¦×œ×—×•×ª ×•×˜×¨× ×“×™×")

# ---------- ×™×¦×•× PNG (××•×¤×¦×™×•× ×œ×™) ----------
try:
    import kaleido  # noqa
    HAVE_KALEIDO = True
    pio.kaleido.scope.plotlyjs = None
    pio.kaleido.scope.default_scale = 2
except Exception:
    HAVE_KALEIDO = False

PLOTLY_CONFIG = {
    "displaylogo": False,
    "modeBarButtonsToAdd": ["toImage"],
    "toImageButtonOptions": {"format": "png", "scale": 2, "filename": "chart"},
}
def fig_download_png(fig, name: str):
    if not HAVE_KALEIDO:
        return
    try:
        st.download_button(
            f"â¬‡ï¸ ×”×•×¨×“ {name} ×›Ö¾PNG",
            data=fig.to_image(format="png", scale=2),
            file_name=f"{name}.png",
            mime="image/png",
            use_container_width=True,
        )
    except Exception:
        pass

# ---------- ×¢×•×–×¨×™× ----------
def _norm(s: str) -> str:
    if s is None:
        return ""
    return str(s).replace("\u200f","").replace("\u200e","").strip()

def _clean_cat_value(v):
    if pd.isna(v):
        return None
    s = _norm(v)
    if re.fullmatch(r"-?\d+(\.\d+)?", s):
        try:
            f = float(s)
            if f.is_integer():
                s = str(int(f))
        except Exception:
            pass
    return s or None

def normalize_cat_col(series: pd.Series) -> pd.Series:
    return series.map(_clean_cat_value) if series is not None else pd.Series([None])

def parse_any_date(v):
    """×××™×¨ ×˜×§×¡×˜/××¡×¤×¨ (Excel serial)/datetime ×œÖ¾Timestamp; ××—×¨×ª NaT."""
    if pd.isna(v):
        return pd.NaT
    if isinstance(v, (int, float, np.integer, np.floating)):
        # Excel serial (××§×•×¨ 1899-12-30)
        return pd.to_datetime(v, unit="D", origin="1899-12-30", errors="coerce")
    s = _norm(v)
    # ×§×•×“× dayfirst (×›××• 02.01.2024), ×× × ×›×©×œ â€” × ×¡×” ×”×¤×•×š
    dt = pd.to_datetime(s, dayfirst=True, errors="coerce", infer_datetime_format=True)
    if pd.isna(dt):
        dt = pd.to_datetime(s, dayfirst=False, errors="coerce")
    return dt

CITY_STOPWORDS = {
    "×¨×—×•×‘","×¨×—","×©×“×¨×•×ª","×©×“","×“×¨×š","×›×™×›×¨","×›×›×¨","×¡××˜×”","×©×›×•× ×”","×©×›",
    "××¡","×‘×™×ª","×‘× ×™×™×Ÿ","×‘× ×™×Ÿ","×“×™×¨×”","×“","××¡'", "××¡â€™"
}
def extract_city(addr):
    """×× ×¡×” ×œ×—×œ×¥ ××ª ×”×¢×™×¨ ××”×©×“×” '×™×©×•×‘/×›×ª×•×‘×ª' (×œ××©×œ '×”×“×£ ×”×™×•××™ 1 ×™×¨×•×©×œ×™×' â†’ '×™×¨×•×©×œ×™×')."""
    if pd.isna(addr):
        return None
    s = _norm(addr)
    # ×”×¡×¨ ××¡×¤×¨×™× ×•×ª×•×•×™ ××¤×¨×™×“ ×‘×¡×™×¡×™×™×, ×•××—×“ ×¨×•×•×—×™×
    s = re.sub(r"[0-9\-_,./]+", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    if not s:
        return None
    toks = [t for t in s.split(" ") if t and t not in CITY_STOPWORDS]
    if not toks:
        return None
    city = toks[-1]
    # × ×™×¨××•×œ×™× × ×¤×•×¦×™×
    city = (city.replace("×ª\"×", "×ª×œ ××‘×™×‘")
                 .replace("×ª×œ-××‘×™×‘", "×ª×œ ××‘×™×‘")
                 .replace("×™×¨×•×©×œ×", "×™×¨×•×©×œ×™×"))
    return city

def detect_header_row(df_headless: pd.DataFrame, scan_rows: int = 12) -> int:
    """
    ×‘×•×—×¨ ××ª ×©×•×¨×ª ×”×›×•×ª×¨×ª ×”×¡×‘×™×¨×” ×‘×™×•×ª×¨ ××ª×•×š ×”×©×•×¨×•×ª ×”×¨××©×•× ×•×ª.
    × ×•×ª×Ÿ × ×™×§×•×“ ×œ××™×œ×™× ×›××• ×ª××¨×™×š/××•×¢×“/×™×©×•×‘/×™×™×©×•×‘/×¢×™×¨/×¡×™×‘×”/×”×—×œ×˜×”/×”×¢×¨×•×ª/××¡'.
    """
    kws = {
        "×ª××¨×™×š","××•×¢×“","×™×©×•×‘","×™×™×©×•×‘","×¢×™×¨","×›×ª×•×‘×ª","×¡×™×‘×ª","×¡×™×‘×”","×”×—×œ×˜×ª ×¤×§×™×“",
        "×¤×§×™×“ ×™×¢×¨×•×ª ××–×•×¨×™","××–×•×¨×™","×¤×§×™×“ ×™×¢×¨×•×ª ×××©×œ×ª×™","×××©×œ×ª×™","×”×¢×¨×•×ª","××¡'","××¡×¤×¨"
    }
    best_row, best_score = 0, -1
    for r in range(min(scan_rows, len(df_headless))):
        row_vals = [_norm(v) for v in df_headless.iloc[r].tolist()]
        non_empty = sum(1 for v in row_vals if v)
        hits = sum(1 for v in row_vals if any(k in v for k in kws))
        score = hits * 5 + non_empty
        if score > best_score:
            best_score, best_row = score, r
    return best_row

def build_col_map(df_cols) -> dict:
    """××™×¤×•×™ ×¢××•×“×•×ª ×’××™×© â†’ ××¤×ª×—×•×ª ×¤× ×™××™×™×: date, city, reason, regional, gov, notes, idx."""
    col_map_local = {}
    for c in df_cols:
        n = _norm(c)
        if any(k in n for k in ["××¡'", "××¡×¤×¨"]):                 col_map_local.setdefault("idx", c)
        if ("×ª××¨×™×š" in n) or ("××•×¢×“" in n):                      col_map_local.setdefault("date", c)
        if any(k in n for k in ["×™×©×•×‘","×™×™×©×•×‘","×¢×™×¨","×›×ª×•×‘×ª"]): col_map_local.setdefault("city", c)
        if ("×¡×™×‘×ª ×”×’×©×ª" in n) or ("×¡×™×‘×”" in n):                  col_map_local.setdefault("reason", c)
        if ("×¤×§×™×“ ×™×¢×¨×•×ª ××–×•×¨×™" in n) or ("××–×•×¨×™" in n):          col_map_local.setdefault("regional", c)
        if ("×¤×§×™×“ ×™×¢×¨×•×ª ×××©×œ×ª×™" in n) or ("×××©×œ×ª×™" in n):        col_map_local.setdefault("gov", c)
        if "×”×¢×¨×•×ª" in n:                                          col_map_local.setdefault("notes", c)
    return col_map_local

# ---------- ×§×œ×™×˜×ª ×§×•×‘×¥ ----------
with glass_container():
    st.markdown("### ğŸ“¥ ×”×¢×œ××ª ×§×•×‘×¥ ×¢×¨×¢×•×¨×™×")
    f_appeals = st.file_uploader(
        "forestry_and_trees_ararim2024- ×“×•×— ×¢×¨×¢×¨×™×.xlsx",
        type=["xlsx"],
        key="appeals_file",
    )

if f_appeals is None:
    st.info("×™×© ×œ×”×¢×œ×•×ª ×§×•×‘×¥ XLSX ×©×œ ×“×•×— ×¢×¨×¢×•×¨×™×.")
    st.stop()

# ---------- ×§×¨×™××” ×•××™×¤×•×™ ×¢××•×“×•×ª (×›×•×œ×œ ××™×ª×•×¨ ×›×•×ª×¨×ª ×× ××™× ×” ×‘×©×•×¨×” ×”×¨××©×•× ×”) ----------
try:
    appeals_raw = pd.read_excel(f_appeals, sheet_name=0)
except Exception as e:
    st.error(f"×©×’×™××” ×‘×§×¨×™××ª ×”×§×•×‘×¥: {e}")
    st.stop()

col_map = build_col_map(appeals_raw.columns)

# ×× ×—×¡×¨ date/city â€” × ×¡×” ××™×ª×•×¨ ×©×•×¨×ª ×›×•×ª×¨×ª ××•×˜×•××˜×™
if not all(k in col_map for k in ("date", "city")):
    appeals_h = pd.read_excel(f_appeals, sheet_name=0, header=None)
    hdr = detect_header_row(appeals_h, scan_rows=12)
    # ×”×’×“×¨ ×›×•×ª×¨×•×ª ××ª×•×š ×”×©×•×¨×” ×©× ××¦××”, ×•×§×— ××ª ×”×˜×‘×œ×” ××ª×—×ª
    new_cols = [_norm(x) if x is not None else "" for x in appeals_h.iloc[hdr].tolist()]
    appeals_h.columns = new_cols
    appeals_h = appeals_h.iloc[hdr + 1:].reset_index(drop=True)
    # ×”×¡×¨ ×›×¤×™×œ×•×™×•×ª ×©××•×ª ×¢××•×“×•×ª
    appeals_h = appeals_h.loc[:, ~appeals_h.columns.duplicated()]
    appeals_h = appeals_h.dropna(how="all")
    appeals_raw = appeals_h
    col_map = build_col_map(appeals_raw.columns)

# ×‘×“×™×§×” ×¡×•×¤×™×ª
missing = [k for k in ("date", "city") if k not in col_map]
if missing:
    st.error(
        "×—×¡×¨×•×ª ×¢××•×“×•×ª ×—×™×•× ×™×•×ª ×‘×§×•×‘×¥: " + ", ".join(missing)
        + "\n×¢××•×“×•×ª ×©× ×§×¨××• ×‘×¤×•×¢×œ:\n" + ", ".join(map(str, appeals_raw.columns))
    )
    st.stop()

# ---------- ×”×›× ×” ×•×˜×™×•×‘ × ×ª×•× ×™× ----------
ap = appeals_raw.copy()

# ×ª××¨×™×š/×©× ×”
ap["×ª××¨×™×š"] = ap[col_map["date"]].map(parse_any_date)
ap["×©× ×”"]   = ap["×ª××¨×™×š"].dt.year.astype("Int64")

# ×™×™×©×•×‘ (×× ×¨××œ ××ª×•×š ×™×©×•×‘/×›×ª×•×‘×ª)
ap["×™×™×©×•×‘_raw"] = ap[col_map["city"]]
ap["×™×™×©×•×‘_cat"] = ap["×™×™×©×•×‘_raw"].map(extract_city)

# ×©×“×•×ª ×ª×•×›×Ÿ
ap["×¡×™×‘×ª ×¢×¨×¢×•×¨ ×’×•×œ××™×ª"] = ap.get(col_map.get("reason")).astype(str) if "reason" in col_map else ""
ap["×”×—×œ×˜×” ××–×•×¨×™"]  = ap.get(col_map.get("regional")).astype(str) if "regional" in col_map else ""
ap["×”×—×œ×˜×” ×××©×œ×ª×™"] = ap.get(col_map.get("gov")).astype(str) if "gov" in col_map else ""
ap["×”×¢×¨×•×ª"] = ap.get(col_map.get("notes")).astype(str) if "notes" in col_map else ""

# × ×™×¨××•×œ ×¡×™×‘×ª ×¢×¨×¢×•×¨
def map_reason(s):
    s = str(s)
    if re.search(r"×‘×˜×™×—×•×ª", s):     return "×‘×˜×™×—×•×ª"
    if re.search(r"×‘×¨×™××•×ª", s):     return "×‘×¨×™××•×ª"
    if re.search(r"××˜×¨×“", s):       return "××˜×¨×“"
    if re.search(r"×‘× ×™×”|×‘× ×™×™×”", s): return "×‘× ×™×™×”"
    return "××—×¨"
ap["×¡×™×‘×ª ×¢×¨×¢×•×¨"] = ap["×¡×™×‘×ª ×¢×¨×¢×•×¨ ×’×•×œ××™×ª"].map(map_reason)

# ×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨
def map_status(row):
    t = f"{row['×”×—×œ×˜×” ×××©×œ×ª×™']} {row['×”×¢×¨×•×ª']}"
    t = t.replace("\u200f","").replace("\u200e","")
    if re.search(r"× ×›×¨×ª×•.*×˜×¨×|× ×›×¨×ª×•.*×“×™×•×Ÿ|× ×›×¨×ª.*×˜×¨×", t): return "×œ× × ×“×•×Ÿ (×›×‘×¨ × ×›×¨×ª)"
    if re.search(r"×¢×¨×¨\s*×”×ª×§×‘×œ\s*×—×œ×§×™×ª", t): return "×”×ª×§×‘×œ ×—×œ×§×™×ª"
    if re.search(r"×¢×¨×¨\s*×”×ª×§×‘×œ", t):         return "×”×ª×§×‘×œ"
    if re.search(r"×¢×¨×¨\s*× ×“×—×”", t):           return "× ×“×—×”"
    # fallback
    if re.search(r"×”×ª×§×‘×œ\s*×—×œ×§×™×ª", t): return "×”×ª×§×‘×œ ×—×œ×§×™×ª"
    if re.search(r"×”×ª×§×‘×œ", t):         return "×”×ª×§×‘×œ"
    if re.search(r"× ×“×—×”", t):           return "× ×“×—×”"
    return "×œ× ×™×“×•×¢"
ap["×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨"] = ap.apply(map_status, axis=1)

# ×¢×¦×™× ×œ×©×™××•×¨/×©× ×™×¦×œ×• ××ª×•×š ×˜×§×¡×˜
def extract_saved(t):
    t = str(t)
    m = re.search(r"(\d+)\s*×¢×¦(?:×™×)?\s*×œ×©×™××•×¨", t)
    if m: return int(m.group(1))
    return 1 if re.search(r"\b×¢×¥\s*×œ×©×™××•×¨\b", t) else 0
ap["×¢×¦×™× ×œ×©×™××•×¨"] = ap["×”×—×œ×˜×” ×××©×œ×ª×™"].map(extract_saved) + ap["×”×¢×¨×•×ª"].map(extract_saved)

# ×¡×•×’ ×”××§×•×¨ (××” ×”×—×œ×˜×ª ×”××–×•×¨×™)
def src_kind(s):
    s = str(s)
    if re.search(r" ×“×—×” .*×‘×§×©×” |×“×—×” ×‘×§×©×”", s): return "×“×—×™×™×ª ×‘×§×©×”"
    if re.search(r" ××™×©×¨ |××™×©×¨ ×›×¨×™×ª", s):      return "×¨×™×©×™×•×Ÿ ×©××•×©×¨"
    return "××—×¨"
ap["×¡×•×’ ××§×•×¨"] = ap["×”×—×œ×˜×” ××–×•×¨×™"].map(src_kind)

# ---------- ××¡× × ×™× ----------
with glass_container():
    st.markdown("### ğŸ” ××¡× × ×™×")
    c1, c2, c3, c4 = st.columns(4)
    years = sorted([int(y) for y in ap["×©× ×”"].dropna().unique()])
    with c1: f_years  = st.multiselect("×©× ×™×", years, default=years or [])
    with c2: f_cities = st.multiselect("×™×™×©×•×‘×™×", sorted(ap["×™×™×©×•×‘_cat"].dropna().unique()), default=[])
    with c3: f_reason = st.multiselect("×¡×™×‘×ª ×¢×¨×¢×•×¨", ["×‘× ×™×™×”","×‘×˜×™×—×•×ª","××˜×¨×“","×‘×¨×™××•×ª","××—×¨"], default=[])
    with c4: f_stat   = st.multiselect("×¡×˜×˜×•×¡ ×”×—×œ×˜×”", ["×”×ª×§×‘×œ","×”×ª×§×‘×œ ×—×œ×§×™×ª","× ×“×—×”","×œ× × ×“×•×Ÿ (×›×‘×¨ × ×›×¨×ª)","×œ× ×™×“×•×¢"], default=[])

mask = pd.Series(True, index=ap.index)
if f_years:  mask &= ap["×©× ×”"].isin(f_years)
if f_cities: mask &= ap["×™×™×©×•×‘_cat"].isin(f_cities)
if f_reason: mask &= ap["×¡×™×‘×ª ×¢×¨×¢×•×¨"].isin(f_reason)
if f_stat:   mask &= ap["×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨"].isin(f_stat)
apv = ap[mask].copy()

with st.expander("âš™ï¸ Top-N ×™×™×©×•×‘×™×", expanded=True):
    cN, cEx = st.columns([1,3])
    with cN: topN = st.number_input("N ×™×™×©×•×‘×™× ××•×¦×’×™×", 1, 50, 10, 1)
    with cEx:
        excl = st.multiselect("×”×—×¨×’ ×™×™×©×•×‘×™×", sorted(apv["×™×™×©×•×‘_cat"].dropna().unique()), default=[])
if excl:
    apv = apv[~apv["×™×™×©×•×‘_cat"].isin(excl)]

st.markdown("---")

# ---------- KPI ----------
k1,k2,k3,k4 = st.columns(4)
k1.metric("×¡×”\"×› ×¢×¨×¢×•×¨×™× (××¡×•× ×Ÿ)", f"{len(apv):,}")
k2.metric("% ×”×¦×œ×—×”", f"{(apv['×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨'].isin(['×”×ª×§×‘×œ','×”×ª×§×‘×œ ×—×œ×§×™×ª']).mean()*100):.1f}%")
k3.metric("×¢×¦×™× ×œ×©×™××•×¨ (×¡×”\"×›)", f"{int(apv['×¢×¦×™× ×œ×©×™××•×¨'].sum()):,}")
k4.metric("# ×™×™×©×•×‘×™× ×™×™×—×•×“×™×™×", f"{apv['×™×™×©×•×‘_cat'].nunique(dropna=True):,}")

st.markdown("---")

# ---------- ×’×¨×¤×™× / ×©××™×œ×ª×•×ª ----------
# 1) TOP-10 ×™×™×©×•×‘×™× ×‘×›××•×ª ×¢×¨×¢×•×¨×™×
g1 = (apv.groupby("×™×™×©×•×‘_cat").size()
        .sort_values(ascending=False).head(topN)
        .reset_index(name="×¢×¨×¢×•×¨×™×").rename(columns={"×™×™×©×•×‘_cat":"×™×™×©×•×‘"}))
fig1 = px.bar(g1, x="×™×™×©×•×‘", y="×¢×¨×¢×•×¨×™×", title="TOP-10 ×™×™×©×•×‘×™× â€” ×›××•×ª ×¢×¨×¢×•×¨×™×")
st.plotly_chart(fig1, use_container_width=True, config=PLOTLY_CONFIG); fig_download_png(fig1, "appeals_top_cities")

# 2) TOP-10 ×™×™×©×•×‘×™× â€” ×¢×¨×¢×•×¨×™× ×©×”×ª×§×‘×œ×• (××œ×/×—×œ×§×™×ª)
acc = apv[apv["×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨"].isin(["×”×ª×§×‘×œ","×”×ª×§×‘×œ ×—×œ×§×™×ª"])]
g2 = (acc.groupby("×™×™×©×•×‘_cat").size()
        .sort_values(ascending=False).head(topN)
        .reset_index(name="×¢×¨×¢×•×¨×™× ×©×”×ª×§×‘×œ×•").rename(columns={"×™×™×©×•×‘_cat":"×™×™×©×•×‘"}))
fig2 = px.bar(g2, x="×™×™×©×•×‘", y="×¢×¨×¢×•×¨×™× ×©×”×ª×§×‘×œ×•", title="TOP-10 ×™×™×©×•×‘×™× â€” ×¢×¨×¢×•×¨×™× ×©×”×ª×§×‘×œ×• (××œ×/×—×œ×§×™×ª)")
st.plotly_chart(fig2, use_container_width=True, config=PLOTLY_CONFIG); fig_download_png(fig2, "appeals_top_cities_accepted")

# 3) TOP-10 ×™×™×©×•×‘×™× â€” ×¢×¦×™× ×œ×©×™××•×¨/×©× ×™×¦×œ×•
g3 = (apv.groupby("×™×™×©×•×‘_cat")["×¢×¦×™× ×œ×©×™××•×¨"].sum()
        .sort_values(ascending=False).head(topN)
        .reset_index().rename(columns={"×™×™×©×•×‘_cat":"×™×™×©×•×‘"}))
fig3 = px.bar(g3, x="×™×™×©×•×‘", y="×¢×¦×™× ×œ×©×™××•×¨", title="TOP-10 ×™×™×©×•×‘×™× â€” ×¢×¦×™× ×©× ×™×¦×œ×•/×œ×©×™××•×¨")
st.plotly_chart(fig3, use_container_width=True, config=PLOTLY_CONFIG); fig_download_png(fig3, "trees_saved_by_city")

# 4) ×”×¢×¨×¢×•×¨×™× ×”×’×“×•×œ×™× ×©×”×ª×§×‘×œ×• (Top 15 ×œ×¤×™ ×¢×¦×™× ×œ×©×™××•×¨)
big = (apv[apv["×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨"].isin(["×”×ª×§×‘×œ","×”×ª×§×‘×œ ×—×œ×§×™×ª"])]
       .sort_values("×¢×¦×™× ×œ×©×™××•×¨", ascending=False).head(15)
       [["×ª××¨×™×š","×™×™×©×•×‘_cat","×¡×™×‘×ª ×¢×¨×¢×•×¨","×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨","×¢×¦×™× ×œ×©×™××•×¨"]]
       .rename(columns={"×™×™×©×•×‘_cat":"×™×™×©×•×‘"}))
st.markdown("#### ×”×¢×¨×¢×•×¨×™× ×”×’×“×•×œ×™× ×©×”×ª×§×‘×œ×• (Top 15 ×œ×¤×™ ×¢×¦×™× ×œ×©×™××•×¨)")
st.dataframe(big, use_container_width=True)

# 5) ×¢×¨×¢×•×¨×™× ×œ×¤×™ ×¡×•×’ ××§×•×¨ (+ ××—×•×–×™ ×”×¦×œ×—×”)
g5c = apv.groupby("×¡×•×’ ××§×•×¨").size().reset_index(name="××¡×¤×¨ ×¢×¨×¢×•×¨×™×")
g5s = (apv.assign(×”×¦×œ×—×”=apv["×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨"].isin(["×”×ª×§×‘×œ","×”×ª×§×‘×œ ×—×œ×§×™×ª"]).astype(int))
          .groupby("×¡×•×’ ××§×•×¨")["×”×¦×œ×—×”"].mean().mul(100).reset_index(name="××—×•×–×™ ×”×¦×œ×—×”"))
g5 = g5c.merge(g5s, on="×¡×•×’ ××§×•×¨", how="left")
fig5 = px.bar(g5, x="×¡×•×’ ××§×•×¨", y="××¡×¤×¨ ×¢×¨×¢×•×¨×™×", text="××—×•×–×™ ×”×¦×œ×—×”",
              title="×¢×¨×¢×•×¨×™× ×œ×¤×™ ×¡×•×’ ××§×•×¨", labels={"××¡×¤×¨ ×¢×¨×¢×•×¨×™×":"×›××•×ª"})
st.plotly_chart(fig5, use_container_width=True, config=PLOTLY_CONFIG); fig_download_png(fig5, "appeals_by_source")

# 6) ××—×•×–×™ ×”×¦×œ×—×” ×œ×¤×™ ×¡×™×‘×ª ×¢×¨×¢×•×¨
g6 = (apv.assign(×”×¦×œ×—×”=apv["×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨"].isin(["×”×ª×§×‘×œ","×”×ª×§×‘×œ ×—×œ×§×™×ª"]).astype(int))
          .groupby("×¡×™×‘×ª ×¢×¨×¢×•×¨")["×”×¦×œ×—×”"].mean().mul(100).reset_index())
fig6 = px.bar(g6.sort_values("×”×¦×œ×—×”", ascending=False),
              x="×¡×™×‘×ª ×¢×¨×¢×•×¨", y="×”×¦×œ×—×”", title="××—×•×–×™ ×”×¦×œ×—×” ×œ×¤×™ ×¡×™×‘×ª ×¢×¨×¢×•×¨",
              labels={"×”×¦×œ×—×”":"% ×”×¦×œ×—×”"})
st.plotly_chart(fig6, use_container_width=True, config=PLOTLY_CONFIG); fig_download_png(fig6, "appeals_success_by_reason")

# 7) ×¢×¨×¢×•×¨×™× ×©×œ× × ×“×•× ×• (×›×‘×¨ × ×›×¨×ª×•)
nd = apv[apv["×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨"] == "×œ× × ×“×•×Ÿ (×›×‘×¨ × ×›×¨×ª)"]
g7 = (nd.groupby("×™×™×©×•×‘_cat").size()
        .sort_values(ascending=False).head(topN)
        .reset_index(name="×¢×¨×¢×•×¨×™× ×©×œ× × ×“×•× ×•").rename(columns={"×™×™×©×•×‘_cat":"×™×™×©×•×‘"}))
if not g7.empty:
    fig7 = px.bar(g7, x="×™×™×©×•×‘", y="×¢×¨×¢×•×¨×™× ×©×œ× × ×“×•× ×•",
                  title="×™×™×©×•×‘×™× â€” ×¢×¨×¢×•×¨×™× ×©×œ× × ×“×•× ×• (×”×¢×¦×™× ×›×‘×¨ × ×›×¨×ª×•)")
    st.plotly_chart(fig7, use_container_width=True, config=PLOTLY_CONFIG); fig_download_png(fig7, "appeals_not_discussed")
else:
    st.info("×œ× × ××¦××• ×¢×¨×¢×•×¨×™× ×©×œ× × ×“×•× ×• (×”×¢×¦×™× ×›×‘×¨ × ×›×¨×ª×•) ×‘××¡× × ×™× ×”× ×•×›×—×™×™×.")

# 8) ×¤×™×œ×•×— ×¡×˜×˜×•×¡ ×›×œ×œ×™
pie = apv.groupby("×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨").size().reset_index(name="××¡×¤×¨")
fig8 = px.pie(pie, names="×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨", values="××¡×¤×¨", title="×¤×™×œ×•×— ×¡×˜×˜×•×¡ ×¢×¨×¢×•×¨×™×")
st.plotly_chart(fig8, use_container_width=True, config=PLOTLY_CONFIG); fig_download_png(fig8, "appeals_status_pie")

st.markdown("---")
st.download_button(
    "â¬‡ï¸ ×”×•×¨×“ CSV â€” ×¢×¨×¢×•×¨×™× (××—×¨×™ ××¡× × ×™×)",
    data=apv.to_csv(index=False).encode("utf-8-sig"),
    file_name="appeals_filtered.csv",
    mime="text/csv",
    use_container_width=True,
)

if not HAVE_KALEIDO:
    st.info("×œ×”×•×¨×“×ª PNG ×”×©×ª××©/×™ ×‘×›×¤×ª×•×¨ ×”××¦×œ××” ×”××•×‘× ×” ×‘×’×¨×£ ××• ×”×ª×§×Ÿ/×™ kaleido.")
