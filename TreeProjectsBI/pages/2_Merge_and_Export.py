# -*- coding: utf-8 -*-
from __future__ import annotations

import io
import re
import numpy as np
import pandas as pd
import streamlit as st
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment

from style_pack import inject_base_css, apply_plotly_theme, hero_header, glass_container
from utils_he import (
    TARGET_COLS,
    map_col,
    detect_header_row,
    clean_text,
)

# ===================== UI / DESIGN =====================
inject_base_css(bg_main="assets/bg_main.jpg", bg_sidebar="assets/bg_sidebar.jpg")
apply_plotly_theme()
hero_header("ğŸ§© Merge & Export", "××™×–×•×’, ×¤×™×¢× ×•×— ×•×”××¨×•×ª â€” ×’×¨×¡×ª BI ××©×•×“×¨×’×ª.")

st.title("ğŸŒ³ forestry_and_trees_report2024 â€” ×“×•×—×•×ª ×›×¨×™×ª×” ××—×•×“")
st.caption(
    "×˜×¢×Ÿ/×™: 1) ×§×•×‘×¥ ×”×“×•×—×•×ª ×”×××•×—×“ (×œ×œ× ×¨×©×™××•×ª), "
    "2) ×§×•×‘×¥ '×¨×©×™××ª ×¢×¨×™× ×œ×¤×™ ×§×•×“×™×', "
    "3) ×§×•×‘×¥ '×¨×©×™××ª ×¢×¦×™× ×œ×¤×™ ×§×•×“×™×'."
)

with glass_container():
    main_file = st.file_uploader(
        "ğŸ“ ×§×•×‘×¥ ×“×•×—×•×ª ×›×¨×™×ª×” ××—×•×“ (×œ×œ× ×¨×©×™××•×ª ×¢×¦×™×/×™×™×©×•×‘×™×)",
        type=["xlsx"],
        key="main",
    )
    city_file = st.file_uploader(
        "ğŸ™ï¸ ×§×•×‘×¥ '×¨×©×™××ª ×¢×¨×™× ×œ×¤×™ ×§×•×“×™×'",
        type=["xlsx"],
        key="cities",
    )
    tree_file = st.file_uploader(
        "ğŸŒ³ ×§×•×‘×¥ '×¨×©×™××ª ×¢×¦×™× ×œ×¤×™ ×§×•×“×™×'",
        type=["xlsx"],
        key="trees",
    )

run_btn = st.button("ğŸš€ ×”×¨×¥ ××™×–×•×’ ×•×”××¨×•×ª")


# ===================== HELPERS =====================

def get_series(df: pd.DataFrame, col_name: str) -> pd.Series:
    """×× ×™×© ×¢××•×“×•×ª ×›×¤×•×œ×•×ª ×‘××•×ª×• ×”×©× â€” ×××—×“ ×¢× bfill ×•×œ×•×§×— ×¢××•×“×” ××—×ª."""
    mask = (df.columns == col_name)
    cols = df.loc[:, mask]
    if cols.shape[1] == 0:
        return pd.Series([pd.NA] * len(df), index=df.index)
    if cols.shape[1] == 1:
        return cols.iloc[:, 0]
    return cols.bfill(axis=1).iloc[:, 0]


def safe_to_datetime_series(s: pd.Series) -> pd.Series:
    """×”××¨×ª ×ª××¨×™×›×™× ×œ×¢××™×“×” ×œ×©×’×™××•×ª ×›×•×œ×œ ××¡×¤×¨×™× ×¡×¨×™××œ×™×™× ×©×œ ××§×¡×œ."""
    dt = pd.to_datetime(s, errors="coerce", infer_datetime_format=True, dayfirst=True)
    need = dt.isna()
    if need.any():
        numeric = pd.to_numeric(s[need], errors="coerce")
        good = numeric[numeric.notna()]
        if not good.empty:
            dt.loc[good.index] = pd.to_datetime(
                good,
                unit="D",
                origin="1899-12-30",
                errors="coerce",
            )
    return dt


# ---------- ×¤×™×¢× ×•×— ×§×•×“×™×: ×¤×¢×•×œ×” + ×¡×™×‘×” ----------

ACTION_MAP = {1: "×›×¨×™×ª×”", 2: "×”×¢×ª×§×”"}

REASON_MAP = {
    1: "××—×¨",
    2: "×‘×˜×™×—×•×ª",
    3: "××—×œ×ª ×¢×¥",
    4: "×¡×›× ×” ×‘×¨×™××•×ª×™×ª",
    5: "×‘× ×™×™×”",
    6: "×”×›×©×¨×” ×—×§×œ××™×ª",
    7: "×¢×¥ ××ª",
    8: "×“×™×œ×•×œ ×™×¢×¨",
    9: "×§×¨×™××”",
    10: "×¡× ×™×˜×¦×™×”",
}


def _to_int_or_nan(val):
    if pd.isna(val):
        return np.nan
    try:
        f = float(str(val).strip())
        i = int(f)
        return i if f == i else np.nan
    except Exception:
        return np.nan


def decode_action_reason(df: pd.DataFrame) -> pd.DataFrame:
    """
    ××™×™×¦×¨:
    - ×¤×¢×•×œ×”_××¤×•×¢× ×—×ª
    - ×¤×¢×•×œ×”_××¤×•×¢× ×—×ª (2)
    - ×¡×™×‘×”_××¤×•×¢× ×—×ª
    ×¨×§ ×›××©×¨ ××“×•×‘×¨ ×‘×§×•×“ ××¡×¤×¨×™; ×˜×§×¡×˜ ×—×•×¤×©×™ × ×©××¨ ×›××• ×©×”×•×.
    """
    out = df.copy()

    # ×¤×¢×•×œ×” ×¨××©×™×ª
    if "×¤×¢×•×œ×”" in out.columns:
        act = out["×¤×¢×•×œ×”"].map(_to_int_or_nan)
        out["×¤×¢×•×œ×”_××¤×•×¢× ×—×ª"] = np.where(
            act.notna(),
            act.map(ACTION_MAP).fillna(out["×¤×¢×•×œ×”"].astype(str)),
            out["×¤×¢×•×œ×”"].astype(str),
        )

    # ×¤×¢×•×œ×” ×©× ×™×™×”
    if "×¤×¢×•×œ×” (2)" in out.columns:
        act2 = out["×¤×¢×•×œ×” (2)"].map(_to_int_or_nan)
        out["×¤×¢×•×œ×”_××¤×•×¢× ×—×ª (2)"] = np.where(
            act2.notna(),
            act2.map(ACTION_MAP).fillna(out["×¤×¢×•×œ×” (2)"].astype(str)),
            out["×¤×¢×•×œ×” (2)"].astype(str),
        )

    # ×¡×™×‘×”
    if "×¡×™×‘×”" in out.columns:
        rea = out["×¡×™×‘×”"].map(_to_int_or_nan)
        out["×¡×™×‘×”_××¤×•×¢× ×—×ª"] = np.where(
            rea.notna(),
            rea.map(REASON_MAP).fillna(out["×¡×™×‘×”"].astype(str)),
            out["×¡×™×‘×”"].astype(str),
        )
    elif "×¡×™×‘×”  ××™×œ×•×œ×™×ª" in out.columns:
        out["×¡×™×‘×”_××¤×•×¢× ×—×ª"] = out["×¡×™×‘×”  ××™×œ×•×œ×™×ª"].astype(str)

    return out


def reorder_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    ××¡×“×¨ ××ª ×”×¢××•×“×•×ª ×›×š ×©:
    - '×¤×¢×•×œ×”' ×œ×™×“ '×¤×¢×•×œ×”_××¤×•×¢× ×—×ª'
    - '×¤×¢×•×œ×” (2)' ×œ×™×“ '×¤×¢×•×œ×”_××¤×•×¢× ×—×ª (2)'
    - '×¡×™×‘×”' / '×¡×™×‘×”  ××™×œ×•×œ×™×ª' ×œ×™×“ '×¡×™×‘×”_××¤×•×¢× ×—×ª'
    ×•×©××¨ ×”×¢××•×“×•×ª × ×©××¨×•×ª ×‘××•×ª×• ×¡×“×¨ ×™×—×¡×™.
    """
    cols = list(df.columns)
    new_order: list[str] = []

    # ×¤×¢×•×œ×” 1
    if "×¤×¢×•×œ×”" in cols:
        new_order.append("×¤×¢×•×œ×”")
    if "×¤×¢×•×œ×”_××¤×•×¢× ×—×ª" in cols:
        new_order.append("×¤×¢×•×œ×”_××¤×•×¢× ×—×ª")

    # ×¤×¢×•×œ×” 2
    if "×¤×¢×•×œ×” (2)" in cols:
        new_order.append("×¤×¢×•×œ×” (2)")
    if "×¤×¢×•×œ×”_××¤×•×¢× ×—×ª (2)" in cols:
        new_order.append("×¤×¢×•×œ×”_××¤×•×¢× ×—×ª (2)")

    # ×¡×™×‘×•×ª
    if "×¡×™×‘×”" in cols:
        new_order.append("×¡×™×‘×”")
    if "×¡×™×‘×”_××¤×•×¢× ×—×ª" in cols:
        new_order.append("×¡×™×‘×”_××¤×•×¢× ×—×ª")
    if "×¡×™×‘×”  ××™×œ×•×œ×™×ª" in cols:
        new_order.append("×¡×™×‘×”  ××™×œ×•×œ×™×ª")

    # ×©××¨ ×”×¢××•×“×•×ª ×‘×¡×“×¨ ×”××§×•×¨×™
    for c in cols:
        if c not in new_order:
            new_order.append(c)

    return df[new_order].copy()


# ---------- ×œ×•×§××¤ ×¢×¨×™× / ×¢×¦×™× ××§×‘×¦×™ ×”××¤×ª×— ----------

def _load_city_lut(city_file) -> dict[int, str]:
    """
    ×§×•×¨× ××ª ×§×•×‘×¥ '×¨×©×™××ª ×¢×¨×™× ×œ×¤×™ ×§×•×“×™×' ×’× ××:
    - ×™×© ×›×•×ª×¨×ª ×‘×©×•×¨×” 1
    - ×©×•×¨×” ×¨×™×§×” ××—×¨×™
    - ×©×•×¨×ª ×”×›×•×ª×¨×•×ª ×”×××™×ª×™×ª ×¨×§ ×‘×©×•×¨×” 2/3/4...
    ××—×¤×© ×©×•×¨×” ×©×™×© ×‘×” ×’× '×™×©×•×‘' ×•×’× '×¡××œ'.
    """
    df0 = pd.read_excel(city_file, sheet_name=0, header=None)
    header_row = None

    for i, row in df0.iterrows():
        vals = [str(v) for v in row.tolist()]
        joined = " ".join(vals)
        if ("×™×©×•×‘" in joined) and ("×¡××œ" in joined):
            header_row = i
            break

    if header_row is None:
        raise ValueError("âŒ ×‘×§×•×‘×¥ ×”×¢×¨×™× ×œ× × ××¦××” ×©×•×¨×ª ×›×•×ª×¨×ª ×¢× '×™×©×•×‘' ×•-'×¡××œ ×™×©×•×‘'.")

    headers = [
        "" if pd.isna(v) else str(v).strip()
        for v in df0.iloc[header_row].tolist()
    ]
    df = df0.iloc[header_row + 1:].copy()
    df.columns = headers

    name_col = None
    code_col = None
    for c in df.columns:
        cs = str(c)
        if "×™×©×•×‘" in cs and "×¡××œ" not in cs and name_col is None:
            name_col = c
        if "×¡××œ" in cs and code_col is None:
            code_col = c

    if name_col is None or code_col is None:
        raise ValueError("âŒ ×‘×§×•×‘×¥ ×”×¢×¨×™× ×—×™×™×‘×•×ª ×œ×”×™×•×ª ×¢××•×“×•×ª '×™×©×•×‘' ×•-'×¡××œ ×™×©×•×‘' (××• ×©××•×ª ×“×•××™×).")

    codes = pd.to_numeric(df[code_col], errors="coerce")
    names = df[name_col].astype(str)

    lut: dict[int, str] = {}
    for code, name in zip(codes, names):
        if pd.isna(code):
            continue
        try:
            lut[int(code)] = name.strip()
        except Exception:
            continue
    return lut


def _load_tree_lut(tree_file) -> dict[int, str]:
    """
    ×§×•×¨× ××ª ×§×•×‘×¥ '×¨×©×™××ª ×¢×¦×™× ×œ×¤×™ ×§×•×“×™×' ×’× ××:
    - ×™×© ×›×•×ª×¨×ª ×’×“×•×œ×” ×‘×©×•×¨×” 1 ('×¨×©×™××ª ×¢×¦×™×')
    - ×™×© ×©×•×¨×•×ª ×¨×™×§×•×ª ×‘×××¦×¢
    - ×©×•×¨×ª ×”×›×•×ª×¨×•×ª ×”×××™×ª×™×ª (Tree, ×©× ×¢×¥ ×•×›×•') ××ª×—×™×œ×” ×¨×§ ×‘×©×•×¨×” 3/4...
    """
    df0 = pd.read_excel(tree_file, sheet_name=0, header=None)

    header_row = None

    # 1) ××—×¤×© ×©×•×¨×” ×©×™×© ×‘×” ×¢××•×“×” ×”××›×™×œ×” 'tree'
    for i, row in df0.iterrows():
        cells = ["" if pd.isna(v) else str(v) for v in row.tolist()]
        if any("tree" in c.lower() for c in cells):
            header_row = i
            break

    # 2) ×× ×œ× × ××¦× â€” ×œ×•×§×— ××ª ×”×©×•×¨×” ×”×œ×Ö¾×¨×™×§×” ×”×¨××©×•× ×” ×‘×ª×•×¨ ×›×•×ª×¨×ª
    if header_row is None:
        for i, row in df0.iterrows():
            if not pd.isna(row).all():
                header_row = i
                break

    if header_row is None:
        raise ValueError("âŒ ×‘×§×•×‘×¥ ×”×¢×¦×™× ×œ× × ××¦××” ×©×•×¨×ª ×›×•×ª×¨×ª ××ª××™××” (×¢× ×¢××•×“×ª Tree).")

    headers = [
        "" if pd.isna(v) else str(v).strip()
        for v in df0.iloc[header_row].tolist()
    ]
    df = df0.iloc[header_row + 1:].copy()
    df.columns = headers

    code_col = None
    name_col = None

    # ×¢××•×“×ª ×”×§×•×“ (Tree)
    for c in df.columns:
        if "tree" in str(c).lower():
            code_col = c
            break

    # ×¢××•×“×ª ×©× ×”×¢×¥ ×‘×¢×‘×¨×™×ª (×©× ×¢×¥)
    for c in df.columns:
        cs = str(c)
        if "×©×" in cs and "×¢×¥" in cs:
            name_col = c
            break

    if code_col is None or name_col is None:
        raise ValueError("âŒ ×‘×§×•×‘×¥ ×”×¢×¦×™× ×—×™×™×‘×•×ª ×œ×”×™×•×ª ×¢××•×“×•×ª 'Tree' ×•-'×©× ×¢×¥' (××• ×©××•×ª ×“×•××™×).")

    codes = pd.to_numeric(df[code_col], errors="coerce")
    names = df[name_col].astype(str)

    lut: dict[int, str] = {}
    for code, name in zip(codes, names):
        if pd.isna(code):
            continue
        try:
            lut[int(code)] = name.strip()
        except Exception:
            continue
    return lut


def apply_city_tree_lookups(
    merged: pd.DataFrame,
    city_lut: dict[int, str],
    tree_lut: dict[int, str],
) -> pd.DataFrame:
    """
    ×××™×¨ ×§×•×“×™× â†’ ×©××•×ª ×‘×ª×•×š ×”×“×•×— ×”×××•×–×’:
    - ×‘×¢××•×“×ª '×™×™×©×•×‘' (×× ×™×© ×§×•×“×™× ××¡×¤×¨×™×™×)
    - ×‘×¢××•×“×•×ª ××™×Ÿ ×¢×¥ (×× ×œ×¤×¢××™× ×™×© ×©× ×§×•×“ ××¡×¤×¨×™ ×‘××§×•× ×©×)
    """
    df = merged.copy()

    # ---- ×™×©×•×‘×™× ----
    if "×™×™×©×•×‘" in df.columns:
        codes = pd.to_numeric(df["×™×™×©×•×‘"], errors="coerce")
        mask = codes.notna()
        mapped = codes[mask].astype(int).map(city_lut)
        df.loc[mask & mapped.notna(), "×™×™×©×•×‘"] = mapped[mapped.notna()]

    # ---- ××™× ×™ ×¢×¥ ----
    tree_cols = [
        c for c in df.columns
        if ("×©×   ××™×Ÿ ×¢×¥" in c) or ("×©× ××™×Ÿ ×¢×¥" in c) or (c == "××™×Ÿ ×¢×¥")
    ]
    for col in tree_cols:
        codes = pd.to_numeric(df[col], errors="coerce")
        mask = codes.notna()
        mapped = codes[mask].astype(int).map(tree_lut)
        df.loc[mask & mapped.notna(), col] = mapped[mapped.notna()]

    return df


# ---------- ×¡×™×•×•×’ ×¤×¢×•×œ×”: ×›×¨×™×ª×” / ×”×¢×ª×§×” ----------

EXCLUDE_PRUNE = r"(×“×™×œ×•×œ|×’×™×–×•×|×ª×—×–×•×§×”|×˜×™×¤×•×œ|×—×™×“×•×©\s*×¦××¨×ª|×¢×™×¦×•×‘\s*× ×•×£)"
INCLUDE_CUT = r"(×›×¨×™×ª(?:×”|×•×ª)?|×›×¨×ª|×›×¨×•×ª|×›×¨×™×ª×ª)"
INCLUDE_MOVE = r"(×”×¢×ª×§(?:×”)?|×©×™××•×¨|transplant|preserv)"


def classify_actions(
    df: pd.DataFrame,
    col_act1: str | None,
    col_act2: str | None,
    col_reason: str | None,
):
    """
    ×™×•×¦×¨ ×“×’×œ×™× ×‘×•×œ×™×× ×™×™×:
    - __is_cut__  â†’ ×©×•×¨×ª ×›×¨×™×ª×”
    - __is_move__ â†’ ×©×•×¨×ª ×”×¢×ª×§×”/×©×™××•×¨
    """
    pieces = []
    for c in (col_act1, col_act2, col_reason):
        if c and c in df.columns:
            pieces.append(df[c].astype(str))

    if not pieces:
        txt = pd.Series([""] * len(df), index=df.index)
    else:
        txt = pieces[0]
        for p in pieces[1:]:
            txt = txt.str.cat(p, sep=" ", na_rep="")

    txt = (
        txt.str.replace("\u200f", "", regex=False)
           .str.replace("\u200e", "", regex=False)
           .str.strip()
    )

    prune = txt.str.contains(EXCLUDE_PRUNE, case=False, regex=True, na=False)
    cut = txt.str.contains(INCLUDE_CUT, case=False, regex=True, na=False) & ~prune
    move = txt.str.contains(INCLUDE_MOVE, case=False, regex=True, na=False)

    return cut.fillna(False), move.fillna(False)


# ===================== MAIN RUN =====================

if run_btn:
    if not main_file or not city_file or not tree_file:
        st.error("×× × ×”×¢×œ×” ××ª ×©×œ×•×©×ª ×”×§×‘×¦×™×: ×“×•×—×•×ª, ×¨×©×™××ª ×¢×¨×™×, ×¨×©×™××ª ×¢×¦×™×.")
        st.stop()

    try:
        # 1) ×˜×¢×™× ×ª ×œ×•×§××¤ ×¢×¨×™× / ×¢×¦×™×
        city_lut = _load_city_lut(city_file)
        tree_lut = _load_tree_lut(tree_file)

        # 2) ×§×¨×™××ª ×§×•×‘×¥ ×”×“×•×—×•×ª (×××•×—×“ ×œ×œ× ×’×œ×™×•× ×•×ª ××¤×ª×—)
        xls = pd.ExcelFile(main_file, engine="openpyxl")

        merged_parts: list[pd.DataFrame] = []
        log_rows: list[dict] = []

        for sname in xls.sheet_names:
            df_raw = pd.read_excel(xls, sheet_name=sname, header=None)
            if df_raw.empty:
                continue

            # ×›×•×ª×¨×ª ×××™×ª×™×ª ×©×œ ×”×“×•×— (×—×™×¤×•×© ×‘×©×•×¨×•×ª ×”×¨××©×•× ×•×ª)
            hdr = detect_header_row(df_raw, scan_rows=8)
            headers = [clean_text(c) for c in df_raw.iloc[hdr].tolist()]
            df = df_raw.iloc[hdr + 1:].reset_index(drop=True)

            if len(headers) < df.shape[1]:
                headers += [f"Unnamed_{i}" for i in range(df.shape[1] - len(headers))]
            headers = headers[: df.shape[1]]
            df.columns = headers

            out = pd.DataFrame(index=df.index, columns=TARGET_COLS)
            used = set()

            for c in df.columns:
                tgt = map_col(c)
                if not tgt:
                    log_rows.append({"sheet": sname, "source_column": c, "mapped_to": ""})
                    continue

                ser = get_series(df, c)

                if tgt == "×¤×¢×•×œ×”":
                    if "×¤×¢×•×œ×”" not in used:
                        out["×¤×¢×•×œ×”"] = ser
                        used.add("×¤×¢×•×œ×”")
                    else:
                        out["×¤×¢×•×œ×” (2)"] = ser
                        used.add("×¤×¢×•×œ×” (2)")
                else:
                    out[tgt] = ser
                    used.add(tgt)

                log_rows.append({"sheet": sname, "source_column": c, "mapped_to": tgt})

            out["__source_sheet__"] = sname
            merged_parts.append(out)

        merged = (
            pd.concat(merged_parts, ignore_index=True)
            if merged_parts else pd.DataFrame(columns=TARGET_COLS)
        )

        # 3) ×”××¨×ª ×§×•×“×™× â†’ ×©××•×ª (×™×™×©×•×‘ + ××™×Ÿ ×¢×¥)
        merged = apply_city_tree_lookups(merged, city_lut, tree_lut)

        # 4) ×¤×™×¢× ×•×— ×¤×¢×•×œ×”/×¡×™×‘×” ×œ××œ×œ
        merged = decode_action_reason(merged)

        # 4.5) ×¡×™×“×•×¨ ×”×¢××•×“×•×ª ×›×š ×©×”×§×•×“×™× ×•×”×˜×§×¡×˜ ×™×”×™×• ××—×“ ×œ×™×“ ×”×©× ×™
        merged = reorder_columns(merged)

        # 5) ×ª××¨×™×›×™×
        for c in ("×-×ª××¨×™×š", "×¢×“-×ª××¨×™×š"):
            if c in merged.columns:
                merged[c] = safe_to_datetime_series(merged[c])

        # 6) ×“×’×œ×™ ×›×¨×™×ª×”/×”×¢×ª×§×”
        col_act1 = (
            "×¤×¢×•×œ×”_××¤×•×¢× ×—×ª"
            if "×¤×¢×•×œ×”_××¤×•×¢× ×—×ª" in merged.columns
            else ("×¤×¢×•×œ×”" if "×¤×¢×•×œ×”" in merged.columns else None)
        )
        col_act2 = (
            "×¤×¢×•×œ×”_××¤×•×¢× ×—×ª (2)"
            if "×¤×¢×•×œ×”_××¤×•×¢× ×—×ª (2)" in merged.columns
            else ("×¤×¢×•×œ×” (2)" if "×¤×¢×•×œ×” (2)" in merged.columns else None)
        )
        col_reason = (
            "×¡×™×‘×”_××¤×•×¢× ×—×ª"
            if "×¡×™×‘×”_××¤×•×¢× ×—×ª" in merged.columns
            else (
                "×¡×™×‘×”"
                if "×¡×™×‘×”" in merged.columns
                else ("×¡×™×‘×”  ××™×œ×•×œ×™×ª" if "×¡×™×‘×”  ××™×œ×•×œ×™×ª" in merged.columns else None)
            )
        )

        is_cut, is_move = classify_actions(merged, col_act1, col_act2, col_reason)
        merged["__is_cut__"] = is_cut
        merged["__is_move__"] = is_move

        # 7) ×›×ª×™×‘×” ×œÖ¾Excel + ×¢×™×¦×•×‘ ×¢××•×“×•×ª
        base = io.BytesIO()
        with pd.ExcelWriter(base, engine="openpyxl") as writer:
            merged.to_excel(writer, sheet_name="Merged", index=False)
            pd.DataFrame({"TargetColumns": TARGET_COLS}).to_excel(
                writer, sheet_name="TargetHeaders", index=False
            )
            pd.DataFrame(log_rows).to_excel(
                writer, sheet_name="MappingLog", index=False
            )

        wb = load_workbook(io.BytesIO(base.getvalue()))
        ws = wb["Merged"]
        header = [c.value for c in ws[1]]

        def _set_col_width(name: str, width: int):
            if name in header:
                idx = header.index(name) + 1
                ws.column_dimensions[get_column_letter(idx)].width = width

        # ×ª××¨×™×›×™×
        for name in ("×-×ª××¨×™×š", "×¢×“-×ª××¨×™×š"):
            if name in header:
                i = header.index(name) + 1
                for row in ws.iter_rows(min_row=2, min_col=i, max_col=i, max_row=ws.max_row):
                    cell = row[0]
                    cell.number_format = "yyyy-mm-dd"
                    cell.alignment = Alignment(horizontal="right")
                _set_col_width(name, 16)

        # ×¢××•×“×•×ª ×©×™××•×©×™×•×ª × ×•×¡×¤×•×ª
        _set_col_width("×™×™×©×•×‘", 22)
        _set_col_width("×©×   ××™×Ÿ ×¢×¥", 22)
        _set_col_width("×”×¢×¨×•×ª", 26)
        _set_col_width("×¤×¢×•×œ×”_××¤×•×¢× ×—×ª", 14)
        _set_col_width("×¤×¢×•×œ×”_××¤×•×¢× ×—×ª (2)", 16)
        _set_col_width("×¡×™×‘×”_××¤×•×¢× ×—×ª", 16)

        final = io.BytesIO()
        wb.save(final)

        st.success("âœ… ×”×§×•×‘×¥ ×”×××•×–×’ ×•×”××¤×•×¢× ×— ××•×›×Ÿ ×œ×”×•×¨×“×”.")
        st.download_button(
            "â¬‡ï¸ ×”×•×¨×“ merged_forest_reports_FINAL_dates_fixed.xlsx",
            data=final.getvalue(),
            file_name="merged_forest_reports_FINAL_dates_fixed.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

        with st.expander("×ª×¦×•×’×” ××§×“×™××” (50 ×©×•×¨×•×ª ×¨××©×•× ×•×ª)", expanded=False):
            st.dataframe(merged.head(50))

    except Exception as e:
        st.error(f"×©×’×™××” ×‘×¢×™×‘×•×“ ×”×§×‘×¦×™×: {e}")

else:
    st.info("ğŸ“ ×”×¢×œ×” ××ª ×©×œ×•×©×ª ×”×§×‘×¦×™× ×•×œ×—×¥ ×¢×œ ×”×›×¤×ª×•×¨ ×›×“×™ ×œ×™×¦×•×¨ ×§×•×‘×¥ BI ×××•×—×“.")
